{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SBIN.csv\n",
      "Saved BAJFINANCE.csv\n",
      "Saved TITAN.csv\n",
      "Saved ITC.csv\n",
      "Saved TCS.csv\n",
      "Saved LT.csv\n",
      "Saved TATACONSUM.csv\n",
      "Saved RELIANCE.csv\n",
      "Saved HCLTECH.csv\n",
      "Saved JSWSTEEL.csv\n",
      "Saved ULTRACEMCO.csv\n",
      "Saved POWERGRID.csv\n",
      "Saved INFY.csv\n",
      "Saved TRENT.csv\n",
      "Saved BHARTIARTL.csv\n",
      "Saved TATAMOTORS.csv\n",
      "Saved WIPRO.csv\n",
      "Saved TECHM.csv\n",
      "Saved NTPC.csv\n",
      "Saved HINDUNILVR.csv\n",
      "Saved APOLLOHOSP.csv\n",
      "Saved M&M.csv\n",
      "Saved GRASIM.csv\n",
      "Saved ICICIBANK.csv\n",
      "Saved ADANIENT.csv\n",
      "Saved ADANIPORTS.csv\n",
      "Saved BEL.csv\n",
      "Saved BAJAJFINSV.csv\n",
      "Saved EICHERMOT.csv\n",
      "Saved COALINDIA.csv\n",
      "Saved MARUTI.csv\n",
      "Saved INDUSINDBK.csv\n",
      "Saved ASIANPAINT.csv\n",
      "Saved TATASTEEL.csv\n",
      "Saved HDFCLIFE.csv\n",
      "Saved DRREDDY.csv\n",
      "Saved SUNPHARMA.csv\n",
      "Saved KOTAKBANK.csv\n",
      "Saved SHRIRAMFIN.csv\n",
      "Saved NESTLEIND.csv\n",
      "Saved ONGC.csv\n",
      "Saved CIPLA.csv\n",
      "Saved BPCL.csv\n",
      "Saved BRITANNIA.csv\n",
      "Saved SBILIFE.csv\n",
      "Saved HINDALCO.csv\n",
      "Saved HEROMOTOCO.csv\n",
      "Saved AXISBANK.csv\n",
      "Saved HDFCBANK.csv\n",
      "Saved BAJAJ-AUTO.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAVEEN\\AppData\\Local\\Temp\\ipykernel_23800\\2507924581.py:300: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sec_[row[1]] = row[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "databse succesfully created in mysql\n",
      " stock_details TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      " stock_details values are successfully inserted in the table\n",
      "Top_10_Green_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "Top_10_Green_Stocks values are successfully inserted in the table\n",
      "Top_10_Loss_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "Top_10_Loss_Stocks values are successfully inserted in the table\n",
      "Avg_prices_per_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "Avg_prices_per_stocks values are successfully inserted in the table\n",
      "Avg_Volume_per_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "Avg_Volume_per_stocks values are successfully inserted in the table\n",
      "No_green_red_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "No_green_red_stocks values are successfully inserted in the table\n",
      "Top_10_Most_Volatile_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "Top_10_Most_Volatile_Stocks values are successfully inserted in the table\n",
      "comulative_return_year TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "comulative_return_year values are successfully inserted in the table\n",
      "sector_wise_overall_return TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "sector_wise_overall_return values are successfully inserted in the table\n",
      "correlation_matrix for Each stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "correlation_matrix for Each stocks values are successfully inserted in the table\n",
      "month_wise_return for Each stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\n",
      "month_wise_return for Each stocks values are successfully inserted in the table\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "# Dictionary of folder paths\n",
    "folder_path_main = {\n",
    "    \"folder_path_1\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2023-10\",\n",
    "    \"folder_path_2\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2023-11\",\n",
    "    \"folder_path_3\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2023-12\",\n",
    "    \"folder_path_4\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-01\",\n",
    "    \"folder_path_5\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-02\",\n",
    "    \"folder_path_6\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-03\",\n",
    "    \"folder_path_7\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-04\",\n",
    "    \"folder_path_8\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-05\",\n",
    "    \"folder_path_9\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-06\",\n",
    "    \"folder_path_10\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-07\",\n",
    "    \"folder_path_11\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-08\",\n",
    "    \"folder_path_12\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-09\",\n",
    "    \"folder_path_13\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-10\",\n",
    "    \"folder_path_14\": \"C:/Users/NAVEEN/OneDrive/Desktop/extract_Data/2024-11\",\n",
    "}\n",
    "#create the function with arugemnt(folder) for getting all the values in folder_path_main(dictinoary)\n",
    "def get_folder_path(folder):\n",
    "    folder_path = folder_path_main[folder]\n",
    "    #using try block to avoid the error (yaml contains unorder date)\n",
    "    try:\n",
    "        # Get all files in the folder\n",
    "        items = os.listdir(folder_path) \n",
    "        # Initialize an empty DataFrame \n",
    "        month = pd.DataFrame()  \n",
    "        #using for loop for iterate the each yaml file in every single folder\n",
    "        for i in items:\n",
    "            # file_path(Correct variable) to joining the each yaml file with folder path\n",
    "            file_path = os.path.join(folder_path, i) \n",
    "            # To the Read the file_path  \n",
    "            with open(file_path, 'r') as file:\n",
    "                # To load the yaml file\n",
    "                data = yaml.safe_load(file)\n",
    "                df = pd.DataFrame(data)\n",
    "                # Correct order of concatenation # Merge DataFrames\n",
    "                month = pd.concat([month, df], ignore_index=True)  \n",
    "\n",
    "        return month  # Return the final DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None  # Return None in case of an error\n",
    "\n",
    "# get the values of each folder_path and store in varible(result)\n",
    "result_1 = get_folder_path(\"folder_path_1\")\n",
    "result_2 = get_folder_path(\"folder_path_2\")\n",
    "result_3 = get_folder_path(\"folder_path_3\")\n",
    "result_4 = get_folder_path(\"folder_path_4\")\n",
    "result_5 = get_folder_path(\"folder_path_5\")\n",
    "result_6 = get_folder_path(\"folder_path_6\")\n",
    "result_7 = get_folder_path(\"folder_path_7\")\n",
    "result_8 = get_folder_path(\"folder_path_8\")\n",
    "result_9 = get_folder_path(\"folder_path_9\")\n",
    "result_10 = get_folder_path(\"folder_path_10\")\n",
    "result_11 = get_folder_path(\"folder_path_11\")\n",
    "result_12 = get_folder_path(\"folder_path_12\")\n",
    "result_13 = get_folder_path(\"folder_path_13\")\n",
    "result_14 = get_folder_path(\"folder_path_14\")\n",
    "# to contact the each result as stored as main_result\n",
    "main_result =  pd.concat([result_1, result_2,result_3,result_4,result_5,result_6,result_7,result_8,result_9,result_10,result_11,result_12,result_13,result_14,], ignore_index=True) \n",
    "\n",
    "#  using for loop to iterate all unique values in Ticker cloumn \n",
    "for ticker in main_result[\"Ticker\"].unique():\n",
    "    df_ticker = main_result[main_result[\"Ticker\"] == ticker]\n",
    "    # To save categoery based Ticker as csv_files for future analysis\n",
    "    df_ticker.to_csv(f\"{ticker}.csv\", index=False)\n",
    "    print(f\"Saved {ticker}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Creating a list to store each ticker's DataFrame\n",
    "df_list = []\n",
    "\n",
    "# using for loop to iterate all unqiue values in Ticker column\n",
    "for ticker in main_result[\"Ticker\"].unique():\n",
    "    df_ticker = main_result[main_result[\"Ticker\"] == ticker]\n",
    "    df_list.append(df_ticker)  # Add each filtered DataFrame to the list\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save to a single CSV file\n",
    "final_df.to_csv(\"All_Tickers.csv\", index=False)\n",
    "\n",
    "#To read the csv file\n",
    "final_stock  = pd.read_csv(\"All_Tickers.csv\")\n",
    "\n",
    "#To convert the date column is in datetime format\n",
    "final_stock['date'] = pd.to_datetime(final_stock['date'])\n",
    "\n",
    "# Exract year from the date column\n",
    "final_stock['year'] = final_stock['date'].dt.year\n",
    "\n",
    "# Exract year from the date column\n",
    "final_stock['months'] = final_stock['date'].dt.month\n",
    "\n",
    "# Exract year from the date column\n",
    "final_stock['day'] = final_stock['date'].dt.day\n",
    "\n",
    "\n",
    "\n",
    "#Year wise anlaysis part\n",
    "\n",
    "#To calculate the ticker_wise_stock for year_wise(2023_2024)for each Ticker\n",
    "\n",
    "# To create the List\n",
    "year_price = []\n",
    "tickers = []\n",
    "#using for loop to calculate open and closing stock year wise\n",
    "for i in final_stock['Ticker'].unique():\n",
    "    # using this variable(Ticker_unique) to get each Ticker values\n",
    "    Ticker_unique = final_stock[final_stock['Ticker'] == i]\n",
    "    #using this varaible(year_trend)to calculate the value for yearwise using iloc function(row_wise_index)\n",
    "    year_trend = ((Ticker_unique.iloc[-1]['close'] - Ticker_unique.iloc[0]['open'])/Ticker_unique.iloc[-1]['open'])*100\n",
    "    #To append the ticker_value\n",
    "    tickers.append(i)\n",
    "    # To append the year_trend\n",
    "    year_price.append(year_trend) \n",
    "\n",
    "# To creat the dataframe \n",
    "year_data = pd.DataFrame({'Ticker': tickers, 'stock_price_year': year_price})\n",
    "\n",
    "# Top_10 Green_Stcoks for year_wise\n",
    "Top_10_Green_Stocks = year_data.sort_values(by= 'stock_price_year', ascending=False).head(10)\n",
    "#To reset the index value \n",
    "Top_10_Green_Stocks = Top_10_Green_Stocks.reset_index(drop=True)\n",
    "\n",
    "# Save to a single CSV file\n",
    "Top_10_Green_Stocks.to_csv(\"Top_10_Green_Stocks\", index=False)\n",
    "\n",
    "# Top_10 Loss_ Stcoks for year_wise\n",
    "Top_10_Loss_Stocks = year_data.sort_values(by='stock_price_year', ascending=False).tail(10)\n",
    "\n",
    "#To reset the index value \n",
    "Top_10_Loss_Stocks = Top_10_Loss_Stocks.reset_index(drop=True)\n",
    "\n",
    "# Save to a single CSV file\n",
    "Top_10_Loss_Stocks.to_csv(\"Top_10_Loss_Stocks\", index=False)\n",
    "\n",
    "#Average volume for Each strock over the Year\n",
    "Avg_Volume_per_stocks = final_stock.groupby(\"Ticker\")[\"volume\"].mean().round(2).reset_index()\n",
    "Avg_Volume_per_stocks = Avg_Volume_per_stocks.rename(columns={\"volume\":\"Avg_volume\"})\n",
    "\n",
    "# Save to a single CSV file\n",
    "Avg_Volume_per_stocks.to_csv(\"Avg_Volume_per_stocks\", index=False)\n",
    "\n",
    "\n",
    "#Average Price for Each strock over the Year\n",
    "Avg_prices_per_stocks = final_stock.groupby(\"Ticker\")[\"close\"].mean().reset_index()\n",
    "Avg_prices_per_stocks = Avg_prices_per_stocks.rename(columns={\"close\": \"Avg_Close_Price\"})\n",
    "\n",
    "# Save to a single CSV file\n",
    "Avg_prices_per_stocks.to_csv(\"Avg_prices_per_stocks\", index=False)\n",
    "\n",
    "# To calculate the Number of Green and Red stcoks over the Year\n",
    "green_stocks = (final_stock[\"close\"] > final_stock[\"open\"]).sum()\n",
    "red_stocks = (final_stock[\"close\"] < final_stock[\"open\"]).sum()\n",
    "\n",
    "\n",
    "# Creating a DataFrame with an index\n",
    "No_green_red_stocks = pd.DataFrame({\n",
    "            \"Stock Type\": [\"Green Stocks\", \"Red Stocks\"],\n",
    "            \"Count\": [green_stocks, red_stocks]})\n",
    "\n",
    "\n",
    "# Save to a single CSV file\n",
    "No_green_red_stocks.to_csv(\"No_green_red_stocks\", index=False)\n",
    "\n",
    "\n",
    "#  Volatility Analysis part\n",
    "\n",
    "#To create the New column using the prevoius column with shift operation\n",
    "final_stock['pre_close'] = final_stock['close'].shift(1)\n",
    "\n",
    "#using For loop to do calculate daily Return for each stock in single day\n",
    "for i in final_stock[\"Ticker\"]:\n",
    "    final_stock['daily_return'] = (final_stock['close'] - final_stock['pre_close']) / final_stock['pre_close']\n",
    "\n",
    "# After that i will check any null values in my dataset\n",
    "\n",
    "# we have 1(Null_values) in my first Row of dataset (final_Stock.iloc[0])\n",
    "\n",
    "#so i will drop my null values using dropna method\n",
    "final_stock.dropna(inplace=True)\n",
    "\n",
    "#To calculate the mean value for daily_return for each Tickers(stocks)\n",
    "#using reset_index to get proper index values\n",
    "AVG_per_Stocks_day = final_stock.groupby('Ticker')[\"daily_return\"].mean().reset_index()\n",
    "\n",
    "#Top 10 Most volatile stocks over the year using head function\n",
    "Top_10_Most_Volatile_Stocks = AVG_per_Stocks_day.sort_values(\"daily_return\",ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "# Save to a single CSV file\n",
    "Top_10_Most_Volatile_Stocks.to_csv(\"Top_10_Most_Volatile_Stocks\", index=False)\n",
    "\n",
    "\n",
    "#Comulative Analysis part\n",
    "\n",
    "#To create the list \n",
    "comulative_return = []\n",
    "comulative_ticker = []\n",
    "\n",
    "#using For loop for each Ticker values to calculate the comulatuive values\n",
    "for i in final_stock[\"Ticker\"].unique():\n",
    "    com_Ticker = final_stock[final_stock[\"Ticker\"] == i]\n",
    "\n",
    "    #using iloc method to choose specific rows in single cloumn(\"close\") in dataframe\n",
    "    com_return = (com_Ticker.iloc[0][\"close\"] - com_Ticker.iloc[-1][\"close\"]) / com_Ticker.iloc[0][\"close\"]*100\n",
    "    #To append the values in the list\n",
    "    comulative_ticker.append(i)  \n",
    "    comulative_return.append(com_return)  \n",
    "\n",
    "#To create the variable for the process of dataframe \n",
    "comulative_return_year = pd.DataFrame({\n",
    "    \"Ticker\": comulative_ticker, \n",
    "    \"Cumulative Return\": comulative_return\n",
    "})\n",
    "\n",
    "# Save to a single CSV file\n",
    "comulative_return_year.to_csv(\"comulative_return_year\", index=False)\n",
    "\n",
    "\n",
    "# stock price correlation part\n",
    "\n",
    "# Pivot Data: Each stock has a separate column for 'close' price\n",
    "df_pivot = final_stock.pivot(index=\"date\", columns=\"Ticker\", values=\"close\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_pivot.corr()\n",
    "\n",
    "# Taking corrlation matrix column values for the fliteration\n",
    "columns = correlation_matrix.columns\n",
    " # Create the list\n",
    "data = []\n",
    " # Using For loop for iterate both rows and values\n",
    "for i,row in correlation_matrix.iterrows():\n",
    "        for cloumn in columns :\n",
    "            #To add the values in list with dictionary format\n",
    "            data.append({\n",
    "                    \"row\" : i,\n",
    "                    \"cloumn\" : cloumn,\n",
    "                    \"corr\" : row[cloumn]\n",
    "\n",
    "\n",
    "            })\n",
    "\n",
    "#To create the Dataframe\n",
    "corr_data = pd.DataFrame(data)\n",
    "\n",
    "        \n",
    "# Drop rows where corr = 1 (Self-correlation)\n",
    "corr_data = corr_data[corr_data[\"corr\"] != 1.000000]\n",
    "\n",
    "\n",
    " # Function to categorize correlation values\n",
    "def categorize_correlation(value):\n",
    "    if value >= 0.8:\n",
    "        return \"Positive Correlation\"\n",
    "    elif 0.5 <= value < 0.8:\n",
    "        return \"Moderate Correlation\"\n",
    "    elif -0.5 < value < 0.5:\n",
    "        return \"No Correlation\"\n",
    "    else:\n",
    "        return \"Negative Correlation\"\n",
    "    \n",
    "\n",
    "# Apply categorization function\n",
    "corr_data[\"Category\"] = corr_data[\"corr\"].apply(categorize_correlation)\n",
    "\n",
    "# Save to a single CSV file\n",
    "corr_data.to_csv(\"correlation_matrix\", index=False)\n",
    "\n",
    "\n",
    "# Sector Wise Analysis part \n",
    "\n",
    "#To Read the csv file\n",
    "sector = pd.read_csv(\"C:/Users/NAVEEN/Downloads/Sector_data - Sheet1 (2).csv\")\n",
    "\n",
    "#from this csv we can drop the cloumn(company), the cloumn not use in feature pupurose\n",
    "sector.drop(\"COMPANY\",axis=1,inplace=True)\n",
    "# To Rename the cloumn name for Feature pupurose(do the function two dataframe)\n",
    "sector.rename(columns={\"Symbol\":\"Ticker\"},inplace=True)\n",
    "\n",
    "#using split function to split data in ticker cloumn\n",
    "sector[\"Ticker\"] = sector[\"Ticker\"].str.split(\":\").str[1].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "sec_ = {} \n",
    "# Iterate over the DataFrame rows\n",
    "for i, row in sector.iterrows():  \n",
    "# Assign values correctly\n",
    "     sec_[row[1]] = row[0] \n",
    "\n",
    "\n",
    "# To create the cloumn in dataframe and using (None) to avoid the key error\n",
    "final_stock[\"sector\"] = None  \n",
    "\n",
    "#using For loop to iterate the ticker values for mapping\n",
    "for i in final_stock[\"Ticker\"]:\n",
    "\n",
    "    # The iterate values is avaliable in dictionary(sec_)\n",
    "    if i in sec_: \n",
    "        final_stock.loc[final_stock[\"Ticker\"] == i, \"sector\"] = sec_[i]\n",
    "    else:\n",
    "        print(f\"Warning: '{i}' not found in sector mapping\")\n",
    "\n",
    "\n",
    "# Initialize lists to store results\n",
    "overall_returns = []\n",
    "sectors = []\n",
    "tickers = []\n",
    "\n",
    "# Loop through unique Ticker-Sector combinations\n",
    "for ticker in final_stock[\"Ticker\"].unique():\n",
    "    for sector in final_stock[\"sector\"].unique():\n",
    "        \n",
    "        # Filter data for the given Ticker and Sector across all years\n",
    "        overall_data = final_stock[(final_stock[\"Ticker\"] == ticker) & (final_stock[\"sector\"] == sector)]\n",
    "        \n",
    "        # Check if there are at least two rows \n",
    "        try:\n",
    "            # Calculate overall return from first available close to last available close\n",
    "            overall_return = ((overall_data.iloc[-1][\"close\"] - overall_data.iloc[0][\"close\"]) / overall_data.iloc[0][\"close\"]) * 100\n",
    "            \n",
    "            # Append values to lists\n",
    "            tickers.append(ticker)\n",
    "            sectors.append(sector)\n",
    "            overall_returns.append(overall_return)\n",
    "\n",
    "        # Skip this iteration if there's not enough data\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Create DataFrame for results\n",
    "sector_wise_overall_return = pd.DataFrame({\n",
    "    \"Ticker\": tickers,\n",
    "    \"Sector\": sectors,\n",
    "    \"Overall Return (2023-2024)\": overall_returns\n",
    "    })\n",
    "\n",
    "\n",
    "# Save to a single CSV file\n",
    "sector_wise_overall_return.to_csv(\"sector_wise_overall _return\", index=False)\n",
    "\n",
    "\n",
    "# Top 5 Month_Wise_Gainers and Losers part\n",
    "\n",
    "# Compute monthly returns\n",
    "final_stock[\"month_return\"] = ((final_stock[\"close\"] - final_stock[\"open\"]) / final_stock[\"open\"]) * 100\n",
    "\n",
    "# Group by Ticker and Month\n",
    "month_wise_return = final_stock.groupby([\"Ticker\", \"month\"])[\"month_return\"].mean().reset_index()\n",
    "\n",
    "\n",
    "# Save to a single CSV file\n",
    "month_wise_return.to_csv(\"Month_wise_Gainers&Losers\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# datawarehousing part\n",
    "\n",
    "# connection vscode to mysql(database)\n",
    "try:\n",
    "\n",
    "    mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Naveen@090194\"\n",
    "    )\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    # creating the database in mysql\n",
    "    mycursor.execute(\"CREATE DATABASE stock_analysis\")\n",
    "\n",
    "    print(\"databse succesfully created in mysql\")\n",
    "\n",
    "except :\n",
    "    print(\" the database already created\")\n",
    "\n",
    "#create the table for in database(stock_analysis)\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query = ('''CREATE TABLE stock_details (     Ticker  VARCHAR(255), \n",
    "                                                        close   float,\n",
    "                                                        date   DATETIME,\n",
    "                                                        high    float,\n",
    "                                                        low     float,\n",
    "                                                        month   VARCHAR(7),\n",
    "                                                        open    float,\n",
    "                                                        volume  int,\n",
    "                                                        year    int,\n",
    "                                                        months  int,\n",
    "                                                        day     int,\n",
    "                                                        pre_close float,\n",
    "                                                       \tdaily_return float,\n",
    "                                                      \tsector VARCHAR(255),\n",
    "                                                        month_return float,\n",
    "                                                        PRIMARY KEY (Ticker, date) \n",
    "                                                        )''')\n",
    "    mycursor.execute(create_query)\n",
    "\n",
    "    print(\" stock_details TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "except :\n",
    "  print(\" stock_details TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "insert_values = final_stock.values.tolist()\n",
    "\n",
    "#To store in values in the stcok_details table\n",
    "try:\n",
    "\n",
    "    insert_query = ''' insert into stock_details \n",
    "                     values\n",
    "                     (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "    mycursor.executemany(insert_query,insert_values)   \n",
    "    mydb.commit()\n",
    "    print(\" stock_details values are successfully inserted in the table\")\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\" stock_details values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(Top_10_green_stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_1 = ('''CREATE TABLE Top_10_green_stocks( Ticker  VARCHAR(255), \n",
    "                                                            stock_price_year float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_1)\n",
    "\n",
    "    print(\"Top_10_Green_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"Top_10_Green_Stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "Top_10_green_values = Top_10_Green_Stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the Top_10_green_stocks\n",
    "try:\n",
    "\n",
    "    insert_query_1 = ''' insert into  Top_10_green_stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_1,Top_10_green_values)   \n",
    "    mydb.commit()\n",
    "    print(\"Top_10_Green_Stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"Top_10_Green_Stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(Top_10_Loss_Stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_2 = ('''CREATE TABLE Top_10_Loss_Stocks( Ticker  VARCHAR(255), \n",
    "                                                            stock_price_year float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_2)\n",
    "\n",
    "    print(\"Top_10_Loss_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"Top_10_Loss_Stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "Top_10_loss_values = Top_10_Loss_Stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the Top_10_Loss_Stocks\n",
    "try:\n",
    "\n",
    "    insert_query_2 = ''' insert into Top_10_Loss_Stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_2,Top_10_loss_values)   \n",
    "    mydb.commit()\n",
    "    print(\"Top_10_Loss_Stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"Top_10_Loss_Stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(Avg_prices_per_stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_3 = ('''CREATE TABLE Avg_prices_per_stocks( Ticker  VARCHAR(255), \n",
    "                                                              Avg_Close_Price float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_3)\n",
    "\n",
    "    print(\"Avg_prices_per_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"Avg_prices_per_stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "Average_price_values = Avg_prices_per_stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the Avg_prices_per_stocks\n",
    "try:\n",
    "\n",
    "    insert_query_3 = ''' insert into  Avg_prices_per_stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_3,Average_price_values)   \n",
    "    mydb.commit()\n",
    "    print(\"Avg_prices_per_stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"Avg_prices_per_stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(Avg_Volume_per_stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_4 = ('''CREATE TABLE Avg_Volume_per_stocks( Ticker  VARCHAR(255), \n",
    "                                                              Avg_volume_Price float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_4)\n",
    "\n",
    "    print(\"Avg_Volume_per_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"Avg_Volume_per_stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "Average_volume_values=Avg_Volume_per_stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the Avg_Volume_per_stocks\n",
    "try:\n",
    "\n",
    "    insert_query_4 = ''' insert into  Avg_Volume_per_stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_4,Average_volume_values)   \n",
    "    mydb.commit()\n",
    "    print(\"Avg_Volume_per_stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"Avg_Volume_per_stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(No_green_red_stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_5 = ('''CREATE TABLE No_green_red_stocks( Stock_Type  VARCHAR(255), \n",
    "                                                           Count int)''')\n",
    "    \n",
    "    mycursor.execute(create_query_5)\n",
    "\n",
    "    print(\"No_green_red_stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"No_green_red_stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "No_green_red_values = No_green_red_stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the No_green_red_stocks table\n",
    "try:\n",
    "\n",
    "    insert_query_5 = ''' insert into No_green_red_stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_5,No_green_red_values)   \n",
    "    mydb.commit()\n",
    "    print(\"No_green_red_stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"No_green_red_stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(Top_10_Most_Volatile_Stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_6 = ('''CREATE TABLE Top_10_Most_Volatile_Stocks( Ticker VARCHAR(255), \n",
    "                                                           volatile_retutn float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_6)\n",
    "\n",
    "    print(\"Top_10_Most_Volatile_Stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"Top_10_Most_Volatile_Stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "Top_10_volatile_values =Top_10_Most_Volatile_Stocks.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the Top_10_Most_Volatile_Stocks table\n",
    "try:\n",
    "\n",
    "    insert_query_6 = ''' insert into Top_10_Most_Volatile_Stocks\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_6,Top_10_volatile_values)   \n",
    "    mydb.commit()\n",
    "    print(\"Top_10_Most_Volatile_Stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"Top_10_Most_Volatile_Stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(comulative_return_year)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_7 = ('''CREATE TABLE comulative_return_year( Ticker VARCHAR(255), \n",
    "                                                              Cumulative_Return float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_7)\n",
    "\n",
    "    print(\"comulative_return_year TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"comulative_return_year TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "comu_values = comulative_return_year.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the comulative_return_year\n",
    "try:\n",
    "\n",
    "    insert_query_7 = ''' insert into comulative_return_year\n",
    "                     values(%s,%s)'''\n",
    "    mycursor.executemany(insert_query_7,comu_values)   \n",
    "    mydb.commit()\n",
    "    print(\"comulative_return_year values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"comulative_return_year values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(sector_wise_overall_return)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_8 = ('''CREATE TABLE sector_wise_overall_return( Ticker VARCHAR(255), \n",
    "                                                              \t  Sector VARCHAR(255),\n",
    "                                                                \tOverall_Return float)''')\n",
    "    \n",
    "    mycursor.execute(create_query_8)\n",
    "\n",
    "    print(\"sector_wise_overall_return TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"sector_wise_overall_return TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "sector_values = sector_wise_overall_return.values.tolist()\n",
    "\n",
    "#To store in values in the comulative_return_year\n",
    "try:\n",
    "\n",
    "    insert_query_8 = ''' insert into sector_wise_overall_return\n",
    "                     values(%s,%s,%s)'''\n",
    "    mycursor.executemany(insert_query_8,sector_values)   \n",
    "    mydb.commit()\n",
    "    print(\"sector_wise_overall_return values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"sector_wise_overall_return values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(correlation_matrix for Each stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_9 = ('''CREATE TABLE correlation_matrix (stock_1 VARCHAR(255),\n",
    "                                                          stock_2 VARCHAR(255),\t\n",
    "                                                          corr_values float,\n",
    "                                                          Category VARCHAR(255))''')\n",
    "    \n",
    "    mycursor.execute(create_query_9)\n",
    "\n",
    "    print(\"correlation_matrix for Each stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"correlation_matrix for Each stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "corr_values=corr_data.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the correlation_matrix for Each stocks\n",
    "try:\n",
    "\n",
    "    insert_query_9 = ''' insert into correlation_matrix\n",
    "                     values(%s,%s,%s,%s)'''\n",
    "    mycursor.executemany(insert_query_9,corr_values)   \n",
    "    mydb.commit()\n",
    "    print(\"correlation_matrix for Each stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"correlation_matrix for Each stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create the table for in database(month_wise_return for Each stocks)\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"Naveen@090194\",\n",
    "  database=\"stock_analysis\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "try :\n",
    "      \n",
    "    create_query_10 = ('''CREATE TABLE month_wise_return (Ticker VARCHAR(255),\n",
    "                                                        \tmonth VARCHAR(255),\n",
    "                                                         \tmonth_return float )''')\n",
    "    \n",
    "    mycursor.execute(create_query_10)\n",
    "\n",
    "    print(\"month_wise_return for Each stocks TABLES ARE SUCCESFUULY CREATED IN MYSQL\")\n",
    "    \n",
    "except :\n",
    "  print(\"month_wise_return for Each stocks TABLES ALREADY  IN MYSQL\")\n",
    "\n",
    "# To get the values in dataframe using (.values) and converting to list\n",
    "month_wise_values=month_wise_return.values.tolist()\n",
    "\n",
    "\n",
    "#To store in values in the month_wise_return for Each stocks\n",
    "try:\n",
    "\n",
    "    insert_query_10 = ''' insert into month_wise_return\n",
    "                     values(%s,%s,%s)'''\n",
    "    mycursor.executemany(insert_query_10,month_wise_values)   \n",
    "    mydb.commit()\n",
    "    print(\"month_wise_return for Each stocks values are successfully inserted in the table\")\n",
    "\n",
    "#To avoid the duplicate entry so we can use try and except method    \n",
    "except :\n",
    "    print(\"month_wise_return for Each stocks values are already exist\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
